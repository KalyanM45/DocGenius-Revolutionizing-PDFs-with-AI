from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader
from langchain import hub
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from PIL import Image
from langchain_community.vectorstores import FAISS

load_dotenv()
img = Image.open("./images.jpeg")
st.set_page_config(page_title="DocGenius: æ–‡æ¡£ç”ŸæˆAI", page_icon=img)
st.header("è¯¢é—®æ‚¨çš„PDFğŸ“„")
pdf = st.file_uploader("ä¸Šä¼ æ‚¨çš„PDF", type="pdf")

if pdf is None:
    st.error("è¯·ä¸Šä¼ ä¸€ä¸ªPDFæ–‡ä»¶")
    st.stop()

pdf_reader = PdfReader(pdf)
text = ""
for page in pdf_reader.pages:
    text += page.extract_text() + "\n"

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)

splits = text_splitter.split_text(text)

embeddings = OpenAIEmbeddings()
vectorStore = FAISS.from_texts(splits, embeddings)
retriever = vectorStore.as_retriever()
prompt = hub.pull("rlm/rag-prompt")
llm = ChatOpenAI(model="gpt-4o-mini")


query = st.text_input("è¯¢é—®å…³äºæ‚¨PDFçš„é—®é¢˜")
if query:
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )

    response = rag_chain.invoke(query)

    st.success(response)
